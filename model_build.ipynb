{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/movie-reviews-tf/venv/local/lib/python2.7/site-packages/sklearn/utils/random.py:10: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  from ._random import sample_without_replacement\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "import io\n",
    "import re\n",
    "import glob\n",
    "import tempfile\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform.beam import impl as beam_impl\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata, dataset_schema\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import tfrecordio\n",
    "\n",
    "from scipy.stats import truncnorm\n",
    "\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'/device:GPU:0']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_available_gpus():\n",
    "    devices = device_lib.list_local_devices()\n",
    "    return [d.name for d in devices if d.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gsutil cp gs://djr-data/movie-reviews/aclImdb_v1.tar.gz .\n",
    "#!tar -xzf aclImdb_v1.tar.gz && rm aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gsutil cp gs://djr-data/movie-reviews/glove.twitter.27B.zip .\n",
    "#!unzip glove.twitter.27B.zip -d glove && rm glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into TFRecords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: RE2 does not support constructs for which only backtracking solutions are known to exist. Thus, backreferences and look-around assertions are not supported!  As a result, I can't put this in tf.regex_replace(...), and it must live outside the input serving function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this pulls out our proper nouns and treats them as single words\n",
    "def proper_preprocessing(review):\n",
    "    proper = r\"([A-Z]([a-z]+|\\.)(?:\\s+[A-Z]([a-z]+|\\.))*(?:\\s+[a-z][a-z\\-]+){0,2}\\s+[A-Z]([a-z]+|\\.)(?:\\s+([0-9]+(?:,[0-9]+)?))?)\"\n",
    "    space_between_brackets = r\"[\\.\\s]+(?=[^\\[\\]]*]])\"\n",
    "    brackets = r\"(?:[\\[]{2})(.*?)(?:[\\]]{2})\"\n",
    "    \n",
    "    review = re.sub(proper, '[[\\\\1]]', review)\n",
    "    review = re.sub(space_between_brackets, '~', review)\n",
    "    review = re.sub(brackets, '\\\\1', review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(g, out):\n",
    "    inputs = glob.glob(g)\n",
    "    np.random.shuffle(inputs)\n",
    "    with tf.python_io.TFRecordWriter(out) as writer:\n",
    "        for i in inputs:\n",
    "            label = 1 if i.split('/')[2] == 'pos' else 0\n",
    "            with open(i, 'r') as f:\n",
    "                review = f.read()\n",
    "            \n",
    "            example = tf.train.Example()\n",
    "            example.features.feature['review'].bytes_list.value.append(proper_preprocessing(review))\n",
    "            example.features.feature['label'].int64_list.value.append(label)\n",
    "                                \n",
    "            writer.write(example.SerializeToString())\n",
    "    \n",
    "load_data('aclImdb/train/[posneg]*/*.txt', 'data/train.tfrecord')\n",
    "load_data('aclImdb/test/[posneg]*/*.txt', 'data/test.tfrecord')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TFT to preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema for raw data\n",
    "RAW_DATA_FEATURE = {\n",
    "    'review': tf.FixedLenFeature(shape=[1], dtype=tf.string),\n",
    "    'label': tf.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "RAW_DATA_METADATA = dataset_metadata.DatasetMetadata(\n",
    "    dataset_schema.from_feature_spec(RAW_DATA_FEATURE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -Rf tft_output/transform_fn \n",
    "!rm -Rf tft_output/transformed_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
      "WARNING:root:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    }
   ],
   "source": [
    "# train our tft transformer\n",
    "with beam.Pipeline() as pipeline:\n",
    "    with beam_impl.Context(temp_dir=tempfile.mkdtemp()):\n",
    "        coder = tft.coders.ExampleProtoCoder(RAW_DATA_METADATA.schema)\n",
    "\n",
    "        train_data = (\n",
    "            pipeline\n",
    "            | 'ReadTrain' >> tfrecordio.ReadFromTFRecord('data/train.tfrecord')\n",
    "            | 'DecodeTrain' >> beam.Map(coder.decode))\n",
    "\n",
    "        test_data = (\n",
    "            pipeline\n",
    "            | 'ReadTest' >> tfrecordio.ReadFromTFRecord('data/test.tfrecord')\n",
    "            | 'DecodeTest' >> beam.Map(coder.decode))\n",
    "\n",
    "        \n",
    "        # remove links, tags, quotes, apostraphes\n",
    "        # bracketize proper nouns, names, and numbers\n",
    "        # then lowercase, split by punctuation, and remove low frequency words\n",
    "        def preprocessing_fn(inputs):\n",
    "            remove = '|'.join([\"https?:\\/\\/(www\\.)?([^\\s]*)\", \"<([^>]+)>\", \"\\'\", \"\\\"\"])\n",
    "            punctuation = r\"([.,;!?\\(\\)\\/])+\"\n",
    "            \n",
    "            reviews = tf.reshape(inputs['review'], [-1])\n",
    "            \n",
    "            reviews = tf.regex_replace(reviews, remove, '')\n",
    "            reviews = tf.regex_replace(tf.regex_replace(reviews, punctuation, ' \\\\1 '), r\"\\s+\", ' ')\n",
    "            \n",
    "            for letter in list('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
    "                reviews = tf.regex_replace(reviews, letter, letter.lower())\n",
    "                \n",
    "            terms = tf.string_split(reviews, ' ')\n",
    "            terms_indices = tft.compute_and_apply_vocabulary(terms, frequency_threshold=5, num_oov_buckets=1, vocab_filename='vocab')\n",
    "            \n",
    "            return {\n",
    "                'terms': terms,\n",
    "                'terms_indices': terms_indices,\n",
    "                'label': inputs['label']\n",
    "            }\n",
    "\n",
    "        \n",
    "        (transformed_train_data, transformed_metadata), transform_fn = (\n",
    "            (train_data, RAW_DATA_METADATA)\n",
    "            | 'AnalyzeAndTransform' >> beam_impl.AnalyzeAndTransformDataset(preprocessing_fn))\n",
    "\n",
    "        transformed_test_data, _ = (\n",
    "            ((test_data, RAW_DATA_METADATA), transform_fn)\n",
    "            | 'Transform' >> beam_impl.TransformDataset())\n",
    "        \n",
    "        transformed_data_coder = tft.coders.ExampleProtoCoder(transformed_metadata.schema)\n",
    "\n",
    "        _ = (\n",
    "            transformed_train_data\n",
    "            | 'EncodeTrain' >> beam.Map(transformed_data_coder.encode)\n",
    "            | 'WriteTrain' >> tfrecordio.WriteToTFRecord('data/train_transformed.tfrecord'))\n",
    "\n",
    "        _ = (\n",
    "            transformed_test_data\n",
    "            | 'EncodeTest' >> beam.Map(transformed_data_coder.encode)\n",
    "            | 'WriteTest' >> tfrecordio.WriteToTFRecord('data/test_transformed.tfrecord'))\n",
    "        \n",
    "        _ = (\n",
    "            transform_fn\n",
    "            | 'WriteTransformFn' >> transform_fn_io.WriteTransformFn('tft_output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize word embeddings with [GloVe](https://nlp.stanford.edu/projects/glove/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary\n",
    "tf_transform_output = tft.TFTransformOutput('tft_output')\n",
    "vocab = tf_transform_output.vocabulary_by_name('vocab')\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load glove embeddings\n",
    "embedding_size = 100\n",
    "glove_embeddings = {}\n",
    "\n",
    "with open('glove/glove.twitter.27B.{}d.txt'.format(embedding_size), mode='r') as f:  \n",
    "    for line in f:\n",
    "        values = line.strip().split()\n",
    "        w = values[0]\n",
    "        vectors = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings[w] = vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initialized embedding matrix\n",
    "embedding_matrix = truncnorm.rvs(a=-2, b=2, size=(vocab_size+1, embedding_size))\n",
    "\n",
    "glove_np = pd.DataFrame(glove_embeddings).values\n",
    "glove_mu, glove_std = np.mean(glove_np), np.std(glove_np)\n",
    "        \n",
    "for i, w in enumerate(vocab):\n",
    "    try:\n",
    "        embedding_matrix[i] = np.clip((glove_embeddings[w] - glove_mu)/glove_std, -2, 2)\n",
    "    except KeyError:\n",
    "        pass\n",
    "\n",
    "embedding_matrix = embedding_matrix / math.sqrt(embedding_size)\n",
    "    \n",
    "def embedding_initializer(shape=None, dtype=tf.float32, partition_info=None):  \n",
    "    assert dtype is tf.float32\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input function\n",
    "feature_spec = tf_transform_output.transformed_feature_spec()\n",
    "\n",
    "def input_fn(input_file_pattern, num_epochs=None, batch_size=25, shuffle=True):  \n",
    "    input_file_names = glob.glob(input_file_pattern)\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(input_file_names)\n",
    "    ds = ds.map(lambda x: tf.parse_single_example(x, feature_spec))\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100000)\n",
    "\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    features = ds.make_one_shot_iterator().get_next()\n",
    "    labels = features.pop('label')\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create estimator spec\n",
    "def make_model(features, labels, mode, params, config):\n",
    "\n",
    "    # hyperparameters\n",
    "    dropout = params['dropout']\n",
    "    conv_filters = params['conv_filters']\n",
    "    dense_units = params['dense_units']\n",
    "    learning_start = params['learning_start']\n",
    "    \n",
    "    # set up feature columns\n",
    "    terms = features['terms_indices']\n",
    "    terms = tf.sparse_to_dense(terms.indices, terms.dense_shape, terms.values, default_value=vocab_size)    \n",
    "    terms_embed_seq = tf.contrib.layers.embed_sequence(terms, vocab_size=vocab_size+1, embed_dim=embedding_size, initializer=embedding_initializer)\n",
    "    \n",
    "    # build graph\n",
    "    net = terms_embed_seq\n",
    "    net = tf.layers.dropout(net, rate=dropout, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    net = tf.layers.conv1d(inputs=net, filters=conv_filters, kernel_size=3, strides=1, activation=tf.nn.leaky_relu)\n",
    "    net = tf.reduce_max(input_tensor=net, axis=1)      \n",
    "    net = tf.layers.dense(net, units=dense_units, activation=tf.nn.leaky_relu)\n",
    "    net = tf.layers.dropout(net, rate=dropout, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    logits = tf.layers.dense(net, 2)\n",
    "    \n",
    "    # compute predictions\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    predicted_probs = tf.nn.softmax(logits)\n",
    "    \n",
    "    # generate predictions\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class': predicted_classes,\n",
    "            'prob': predicted_probs\n",
    "        }\n",
    "        \n",
    "        export_outputs = {\n",
    "          'predict': tf.estimator.export.PredictOutput(outputs=predictions)\n",
    "        }\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions, export_outputs=export_outputs)\n",
    "\n",
    "    # compute loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # create training op with cosine annealing for learning rate\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        \n",
    "        learning_rate = tf.train.cosine_decay(learning_rate=learning_start, global_step=global_step, alpha=0.05, decay_steps=5000)\n",
    "        \n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "        optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
    "        \n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # compute evaluation metrics\n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predicted_classes),\n",
    "        'auc': tf.metrics.auc(labels=labels, predictions=predicted_probs[:, 1])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifiers for each set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make hyperparameter grid\n",
    "param_grid = {\n",
    "    'dropout': [0.2, 0.3],\n",
    "    'conv_filters': [50, 100, 200],\n",
    "    'dense_units': [50, 100, 200],\n",
    "    'learning_start': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "param_grid = list(ParameterGrid(param_grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train all our models\n",
    "classifiers = []\n",
    "classifiers_stats = []\n",
    "\n",
    "for p in param_grid:\n",
    "    classifier = tf.estimator.Estimator(model_fn=make_model, params=p,\n",
    "                                        config=tf.estimator.RunConfig(session_config=tf.ConfigProto(log_device_placement=True)))\n",
    "\n",
    "    classifier.train(input_fn=lambda: input_fn('data/train_transformed.tfrecord*', num_epochs=5))\n",
    "    classifier_stats = classifier.evaluate(input_fn=lambda: input_fn('data/test_transformed.tfrecord*', num_epochs=1))\n",
    "    \n",
    "    classifiers.append(classifier)\n",
    "    classifiers_stats.append(classifier_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and select best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_filters': 200,\n",
       " 'dense_units': 200,\n",
       " 'dropout': 0.3,\n",
       " 'learning_start': 0.1}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select best hyperparameters\n",
    "results = zip(param_grid, classifiers, classifiers_stats)\n",
    "results.sort(key=lambda x: -x[2]['auc'])\n",
    "best_params, best_classifier, best_classifier_stats = results[0]\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>0.12346</td>\n",
       "      <td>0.24877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.99162</td>\n",
       "      <td>0.96591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>5000.00000</td>\n",
       "      <td>5000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.95612</td>\n",
       "      <td>0.90092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  train        test\n",
       "loss            0.12346     0.24877\n",
       "auc             0.99162     0.96591\n",
       "global_step  5000.00000  5000.00000\n",
       "accuracy        0.95612     0.90092"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# overall stats\n",
    "train_stats = best_classifier.evaluate(input_fn=lambda: input_fn('data/train_transformed.tfrecord*', num_epochs=1))\n",
    "test_stats = best_classifier.evaluate(input_fn=lambda: input_fn('data/test_transformed.tfrecord*', num_epochs=1))\n",
    "\n",
    "train_stats = pd.DataFrame.from_dict(train_stats, orient='index', columns=['train'])\n",
    "test_stats = pd.DataFrame.from_dict(test_stats, orient='index', columns=['test'])\n",
    "stats = train_stats.join(test_stats)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    review = tf.placeholder(dtype=tf.string)\n",
    "    label = tf.zeros(dtype=tf.int64, shape=[1, 1]) # just a placeholder\n",
    "    \n",
    "    transformed_features = tf_transform_output.transform_raw_features({'review': review, 'label': label})\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(transformed_features, {'review': review})\n",
    "\n",
    "\n",
    "export_path = best_classifier.export_savedmodel(export_dir_base='exports',\n",
    "                                                serving_input_receiver_fn=serving_input_fn)\n",
    "\n",
    "export_path = export_path.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-09-28 19:35:45.244595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero',\n",
       " '2018-09-28 19:35:45.245774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: ',\n",
       " 'name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285',\n",
       " 'pciBusID: 0000:00:04.0',\n",
       " 'totalMemory: 15.90GiB freeMemory: 354.06MiB',\n",
       " '2018-09-28 19:35:45.245806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0',\n",
       " '2018-09-28 19:35:45.562533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:',\n",
       " '2018-09-28 19:35:45.562583: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 ',\n",
       " '2018-09-28 19:35:45.562592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N ',\n",
       " '2018-09-28 19:35:45.562758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 65 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)',\n",
       " '2018-09-28 19:35:46.675556: W tensorflow/core/common_runtime/bfc_allocator.cc:219] Allocator (GPU_0_bfc) ran out of memory trying to allocate 44.61MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.',\n",
       " 'Result for output key class:',\n",
       " '[0 1]',\n",
       " 'Result for output key prob:',\n",
       " '[[0.9713119  0.0286881 ]',\n",
       " ' [0.05546241 0.9445375 ]]']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!venv/bin/saved_model_cli run --input_exprs 'review=[\"this is a terrible movie\", \"this is a great movie\"]'  \\\n",
    "--dir $export_path --tag_set serve --signature_def predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "movie-reviews",
   "language": "python",
   "name": "movie-reviews"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
