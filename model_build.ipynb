{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import io\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "train_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
    "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
    "test_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
    "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def parse_fn(record):\n",
    "    features = {\n",
    "        \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n",
    "        \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n",
    "    }\n",
    "  \n",
    "    parsed_features = tf.parse_single_example(record, features)\n",
    "\n",
    "    terms = parsed_features['terms'].values\n",
    "    labels = parsed_features['labels']\n",
    "\n",
    "    return  {'terms': terms}, labels\n",
    "\n",
    "def input_fn(input_filenames, num_epochs=None, batch_size=25, shuffle=True):  \n",
    "    ds = tf.data.TFRecordDataset(input_filenames)\n",
    "    ds = ds.map(parse_fn)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100000)\n",
    "\n",
    "    ds = ds.padded_batch(batch_size, ds.output_shapes).repeat(num_epochs)\n",
    "\n",
    "    return ds.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the vocabulary file.\n",
    "terms_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/terms.txt'\n",
    "terms_path = tf.keras.utils.get_file(terms_url.split('/')[-1], terms_url)\n",
    "\n",
    "vocab = None\n",
    "with io.open(terms_path, 'r', encoding='utf8') as f:\n",
    "    vocab = list(set(f.read().split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier\n",
    "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key='terms', \n",
    "                                                                                 vocabulary_list=vocab)\n",
    "\n",
    "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=10)\n",
    "feature_columns = [terms_embedding_column]\n",
    "\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[10, 10],\n",
    "    dropout=0.3,\n",
    "    activation_fn=tf.nn.leaky_relu,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7fcf06c24b38>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "classifier.train(input_fn=lambda: input_fn([train_path], num_epochs=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.955800</td>\n",
       "      <td>0.875120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.986446</td>\n",
       "      <td>0.945513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.986157</td>\n",
       "      <td>0.943763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>0.138444</td>\n",
       "      <td>0.344261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>3.461092</td>\n",
       "      <td>8.606529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.956787</td>\n",
       "      <td>0.880230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.494096</td>\n",
       "      <td>0.488580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.954720</td>\n",
       "      <td>0.868400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            train         test\n",
       "accuracy                 0.955800     0.875120\n",
       "accuracy_baseline        0.500000     0.500000\n",
       "auc                      0.986446     0.945513\n",
       "auc_precision_recall     0.986157     0.943763\n",
       "average_loss             0.138444     0.344261\n",
       "label/mean               0.500000     0.500000\n",
       "loss                     3.461092     8.606529\n",
       "precision                0.956787     0.880230\n",
       "prediction/mean          0.494096     0.488580\n",
       "recall                   0.954720     0.868400\n",
       "global_step           5000.000000  5000.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = classifier.evaluate(input_fn=lambda: input_fn([train_path], num_epochs=1))\n",
    "test_stats = classifier.evaluate(input_fn=lambda: input_fn([test_path], num_epochs=1))\n",
    "\n",
    "train_stats = pd.DataFrame.from_dict(train_stats, orient='index', columns=['train'])\n",
    "test_stats = pd.DataFrame.from_dict(test_stats, orient='index', columns=['test'])\n",
    "stats = train_stats.join(test_stats)\n",
    "stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
