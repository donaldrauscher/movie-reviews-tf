{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import io\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "train_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
    "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
    "test_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
    "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def parse_fn(record):\n",
    "    features = {\n",
    "        \"terms\": tf.VarLenFeature(dtype=tf.string), # terms are strings of varying lengths\n",
    "        \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32) # labels are 0 or 1\n",
    "    }\n",
    "  \n",
    "    parsed_features = tf.parse_single_example(record, features)\n",
    "\n",
    "    terms = parsed_features['terms'].values\n",
    "    labels = parsed_features['labels']\n",
    "\n",
    "    return  {'terms': terms}, labels\n",
    "\n",
    "def input_fn(input_filenames, num_epochs=None, batch_size=25, shuffle=True):  \n",
    "    ds = tf.data.TFRecordDataset(input_filenames)\n",
    "    ds = ds.map(parse_fn)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100000)\n",
    "\n",
    "    ds = ds.padded_batch(batch_size, ds.output_shapes).repeat(num_epochs)\n",
    "\n",
    "    return ds.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the vocabulary file.\n",
    "terms_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/terms.txt'\n",
    "terms_path = tf.keras.utils.get_file(terms_url.split('/')[-1], terms_url)\n",
    "\n",
    "vocab = None\n",
    "with io.open(terms_path, 'r', encoding='utf8') as f:\n",
    "    vocab = list(set(f.read().split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classifier\n",
    "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key='terms', \n",
    "                                                                                 vocabulary_list=vocab)\n",
    "\n",
    "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=10)\n",
    "feature_columns = [terms_embedding_column]\n",
    "\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
    "optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
    "\n",
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[10, 10],\n",
    "    dropout=0.3,\n",
    "    activation_fn=tf.nn.leaky_relu,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f76bc3e3ba8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "classifier.train(input_fn=lambda: input_fn([train_path], num_epochs=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.939680</td>\n",
       "      <td>0.875960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy_baseline</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.981543</td>\n",
       "      <td>0.947222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc_precision_recall</th>\n",
       "      <td>0.981743</td>\n",
       "      <td>0.944773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_loss</th>\n",
       "      <td>0.172752</td>\n",
       "      <td>0.322212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label/mean</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>4.318808</td>\n",
       "      <td>8.055312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.953391</td>\n",
       "      <td>0.897286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prediction/mean</th>\n",
       "      <td>0.481224</td>\n",
       "      <td>0.472464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.924560</td>\n",
       "      <td>0.849120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            train         test\n",
       "accuracy                 0.939680     0.875960\n",
       "accuracy_baseline        0.500000     0.500000\n",
       "auc                      0.981543     0.947222\n",
       "auc_precision_recall     0.981743     0.944773\n",
       "average_loss             0.172752     0.322212\n",
       "label/mean               0.500000     0.500000\n",
       "loss                     4.318808     8.055312\n",
       "precision                0.953391     0.897286\n",
       "prediction/mean          0.481224     0.472464\n",
       "recall                   0.924560     0.849120\n",
       "global_step           5000.000000  5000.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = classifier.evaluate(input_fn=lambda: input_fn([train_path], num_epochs=1))\n",
    "test_stats = classifier.evaluate(input_fn=lambda: input_fn([test_path], num_epochs=1))\n",
    "\n",
    "train_stats = pd.DataFrame.from_dict(train_stats, orient='index', columns=['train'])\n",
    "test_stats = pd.DataFrame.from_dict(test_stats, orient='index', columns=['test'])\n",
    "stats = train_stats.join(test_stats)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    reviews = tf.placeholder(dtype=tf.string, shape=(None), name='reviews')\n",
    "    terms = tf.sparse_tensor_to_dense(tf.string_split(reviews), default_value='')\n",
    "    return tf.estimator.export.ServingInputReceiver({'terms': terms}, {'reviews': reviews})\n",
    "\n",
    "\n",
    "export_path = classifier.export_savedmodel(export_dir_base='exports',\n",
    "                                           serving_input_receiver_fn=serving_input_receiver_fn)\n",
    "\n",
    "export_path = export_path.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-08-28 21:48:37.864805: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       " '/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88',\n",
       " '  return f(*args, **kwds)',\n",
       " '/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88',\n",
       " '  return f(*args, **kwds)',\n",
       " 'Result for output key class_ids:',\n",
       " '[[0]',\n",
       " ' [1]]',\n",
       " 'Result for output key classes:',\n",
       " \"[[b'0']\",\n",
       " \" [b'1']]\",\n",
       " 'Result for output key logistic:',\n",
       " '[[6.125786e-16]',\n",
       " ' [1.000000e+00]]',\n",
       " 'Result for output key logits:',\n",
       " '[[-35.028854]',\n",
       " ' [ 22.839   ]]',\n",
       " 'Result for output key probabilities:',\n",
       " '[[1.0000000e+00 6.1257862e-16]',\n",
       " ' [1.2054467e-10 1.0000000e+00]]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!saved_model_cli run --input_exprs 'reviews=[\"this is a terrible movie\", \"this is a great movie\"]'  \\\n",
    "--dir $export_path --tag_set serve --signature_def predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
