{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import io\n",
    "import re\n",
    "import glob\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform.beam import impl as beam_impl\n",
    "from tensorflow_transform.beam.tft_beam_io import transform_fn_io\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata, dataset_schema\n",
    "\n",
    "import apache_beam as beam\n",
    "from apache_beam.io import tfrecordio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(g, out):\n",
    "    inputs = glob.glob(g)\n",
    "    np.random.shuffle(inputs)\n",
    "    with tf.python_io.TFRecordWriter(out) as writer:\n",
    "        for i in inputs:\n",
    "            label = 1 if i.split('/')[2] == 'pos' else 0\n",
    "            with open(i, 'r') as f:\n",
    "                review = f.read()\n",
    "            \n",
    "            example = tf.train.Example()\n",
    "            example.features.feature['review'].bytes_list.value.append(review)\n",
    "            example.features.feature['label'].int64_list.value.append(label)\n",
    "                                \n",
    "            writer.write(example.SerializeToString())\n",
    "    \n",
    "load_data('aclImdb/train/[posneg]*/*.txt', 'data/train.tfrecord')\n",
    "load_data('aclImdb/test/[posneg]*/*.txt', 'data/test.tfrecord')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TFT to preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema for raw data\n",
    "RAW_DATA_FEATURE = {\n",
    "    'review': tf.FixedLenFeature(shape=[1], dtype=tf.string),\n",
    "    'label': tf.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "RAW_DATA_METADATA = dataset_metadata.DatasetMetadata(\n",
    "    dataset_schema.from_feature_spec(RAW_DATA_FEATURE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -Rf tft_output/transform_fn \n",
    "!rm -Rf tft_output/transformed_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n",
      "WARNING:root:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    }
   ],
   "source": [
    "# train our tft transformer\n",
    "with beam.Pipeline() as pipeline:\n",
    "    with beam_impl.Context(temp_dir=tempfile.mkdtemp()):\n",
    "        coder = tft.coders.ExampleProtoCoder(RAW_DATA_METADATA.schema)\n",
    "\n",
    "        train_data = (\n",
    "            pipeline\n",
    "            | 'ReadTrain' >> tfrecordio.ReadFromTFRecord('data/train.tfrecord')\n",
    "            | 'DecodeTrain' >> beam.Map(coder.decode))\n",
    "\n",
    "        test_data = (\n",
    "            pipeline\n",
    "            | 'ReadTest' >> tfrecordio.ReadFromTFRecord('data/test.tfrecord')\n",
    "            | 'DecodeTest' >> beam.Map(coder.decode))\n",
    "\n",
    "        \n",
    "        # remove links, tags, quotes, apostraphes, and number commas\n",
    "        # then lowercase, split by punctuation, and remove low frequency words\n",
    "        def preprocessing_fn(inputs):\n",
    "            remove = [\"https?:\\/\\/(www\\.)?([^\\s]*)\", \"<([^>]+)>\", \"\\'\", \"\\\"\"]\n",
    "            remove = '|'.join(remove)\n",
    "            \n",
    "            reviews = tf.reshape(inputs['review'], [-1])\n",
    "            reviews = tf.regex_replace(reviews, remove, '')\n",
    "            reviews = tf.regex_replace(reviews, r\"([0-9]),([0-9])\", '\\\\1\\\\2')\n",
    "            \n",
    "            for letter in list('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
    "                reviews = tf.regex_replace(reviews, letter, letter.lower())\n",
    "                \n",
    "            terms = tf.string_split(reviews, '.,!?() ')\n",
    "            terms_indices = tft.compute_and_apply_vocabulary(terms, frequency_threshold=5, num_oov_buckets=1, vocab_filename='vocab')\n",
    "            \n",
    "            return {\n",
    "                'terms': terms_indices,\n",
    "                'label': inputs['label']\n",
    "            }\n",
    "\n",
    "        \n",
    "        (transformed_train_data, transformed_metadata), transform_fn = (\n",
    "            (train_data, RAW_DATA_METADATA)\n",
    "            | 'AnalyzeAndTransform' >> beam_impl.AnalyzeAndTransformDataset(preprocessing_fn))\n",
    "\n",
    "        transformed_test_data, _ = (\n",
    "            ((test_data, RAW_DATA_METADATA), transform_fn)\n",
    "            | 'Transform' >> beam_impl.TransformDataset())\n",
    "        \n",
    "        transformed_data_coder = tft.coders.ExampleProtoCoder(transformed_metadata.schema)\n",
    "\n",
    "        _ = (\n",
    "            transformed_train_data\n",
    "            | 'EncodeTrain' >> beam.Map(transformed_data_coder.encode)\n",
    "            | 'WriteTrain' >> tfrecordio.WriteToTFRecord('data/train_transformed.tfrecord'))\n",
    "\n",
    "        _ = (\n",
    "            transformed_test_data\n",
    "            | 'EncodeTest' >> beam.Map(transformed_data_coder.encode)\n",
    "            | 'WriteTest' >> tfrecordio.WriteToTFRecord('data/test_transformed.tfrecord'))\n",
    "        \n",
    "        _ = (\n",
    "            transform_fn\n",
    "            | 'WriteTransformFn' >> transform_fn_io.WriteTransformFn('tft_output'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input function\n",
    "feature_spec = transformed_metadata.schema.as_feature_spec()\n",
    "\n",
    "def input_fn(input_file_pattern, num_epochs=None, batch_size=25, shuffle=True):  \n",
    "    input_file_names = glob.glob(input_file_pattern)\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(input_file_names)\n",
    "    ds = ds.map(lambda x: tf.parse_single_example(x, feature_spec))\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100000)\n",
    "\n",
    "    ds = ds.batch(batch_size).repeat(num_epochs)\n",
    "    \n",
    "    features = ds.make_one_shot_iterator().get_next()\n",
    "    labels = features.pop('label')\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get vocabulary size\n",
    "tf_transform_output = tft.TFTransformOutput('tft_output')\n",
    "vocab_size = tf_transform_output.vocabulary_size_by_name('vocab')\n",
    "\n",
    "# set up feature columns\n",
    "terms_col = tf.feature_column.categorical_column_with_identity(key='terms', num_buckets=vocab_size+1)\n",
    "terms_embed_col = tf.feature_column.embedding_column(terms_col, dimension=50, combiner='sqrtn')\n",
    "feature_columns = [terms_embed_col]\n",
    "\n",
    "\n",
    "# create estimator spec\n",
    "def make_model(features, labels, mode):\n",
    "\n",
    "    # build graph\n",
    "    net = tf.feature_column.input_layer(features, feature_columns)\n",
    "    net = tf.layers.dense(net, units=10, activation=tf.nn.leaky_relu)\n",
    "    net = tf.layers.dropout(net, rate=0.3, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    net = tf.layers.dense(net, units=10)\n",
    "    logits = tf.layers.dense(net, 2)\n",
    "    \n",
    "    # compute predictions\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    predicted_probs = tf.nn.softmax(logits)\n",
    "    \n",
    "    # generate predictions\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class': predicted_classes,\n",
    "            'prob': predicted_probs\n",
    "        }\n",
    "        \n",
    "        export_outputs = {\n",
    "          'predict': tf.estimator.export.PredictOutput(outputs=predictions)\n",
    "        }\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions, export_outputs=export_outputs)\n",
    "\n",
    "    # compute loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # create training op with cosine annealing for learning rate\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        \n",
    "        learning_rate = tf.train.cosine_decay_restarts(learning_rate=0.1, global_step=global_step, alpha=0.05, \n",
    "                                                       first_decay_steps=1000, t_mul=2.0, m_mul=0.8)\n",
    "        \n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "        optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
    "        \n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # compute evaluation metrics\n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predicted_classes),\n",
    "        'auc': tf.metrics.auc(labels=labels, predictions=predicted_probs[:, 1])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f6f483327d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "classifier = tf.estimator.Estimator(model_fn=make_model)\n",
    "classifier.train(input_fn=lambda: input_fn('data/train_transformed.tfrecord*', num_epochs=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>0.188809</td>\n",
       "      <td>0.301417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.979024</td>\n",
       "      <td>0.947173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>5000.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.923160</td>\n",
       "      <td>0.876560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   train         test\n",
       "loss            0.188809     0.301417\n",
       "auc             0.979024     0.947173\n",
       "global_step  5000.000000  5000.000000\n",
       "accuracy        0.923160     0.876560"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = classifier.evaluate(input_fn=lambda: input_fn('data/train_transformed.tfrecord*', num_epochs=1))\n",
    "test_stats = classifier.evaluate(input_fn=lambda: input_fn('data/test_transformed.tfrecord*', num_epochs=1))\n",
    "\n",
    "train_stats = pd.DataFrame.from_dict(train_stats, orient='index', columns=['train'])\n",
    "test_stats = pd.DataFrame.from_dict(test_stats, orient='index', columns=['test'])\n",
    "stats = train_stats.join(test_stats)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    review = tf.placeholder(dtype=tf.string)\n",
    "    label = tf.zeros(dtype=tf.int64, shape=[1, 1]) # just a placeholder\n",
    "    \n",
    "    transformed_features = tf_transform_output.transform_raw_features({'review': review, 'label': label})\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(transformed_features, {'review': review})\n",
    "\n",
    "\n",
    "export_path = classifier.export_savedmodel(export_dir_base='exports',\n",
    "                                           serving_input_receiver_fn=serving_input_fn)\n",
    "\n",
    "export_path = export_path.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-09-15 10:25:57.726209: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       " 'Result for output key class:',\n",
       " '[0 1]',\n",
       " 'Result for output key prob:',\n",
       " '[[0.9989225  0.00107747]',\n",
       " ' [0.01596025 0.9840397 ]]']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!saved_model_cli run --input_exprs 'review=[\"this is a terrible movie\", \"this is a great movie\"]'  \\\n",
    "--dir $export_path --tag_set serve --signature_def predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
