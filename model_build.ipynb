{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import io\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "train_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/train.tfrecord'\n",
    "train_path = tf.keras.utils.get_file(train_url.split('/')[-1], train_url)\n",
    "test_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/test.tfrecord'\n",
    "test_path = tf.keras.utils.get_file(test_url.split('/')[-1], test_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "def parse_fn(record):\n",
    "    features = {\n",
    "        \"terms\": tf.VarLenFeature(dtype=tf.string),\n",
    "        \"labels\": tf.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "    }\n",
    "  \n",
    "    parsed_features = tf.parse_single_example(record, features)\n",
    "\n",
    "    terms = parsed_features['terms'].values\n",
    "    labels = tf.cast(parsed_features['labels'], tf.int32)\n",
    "\n",
    "    return  {'terms': terms}, labels\n",
    "\n",
    "def input_fn(input_filenames, num_epochs=None, batch_size=25, shuffle=True):  \n",
    "    ds = tf.data.TFRecordDataset(input_filenames)\n",
    "    ds = ds.map(parse_fn)\n",
    "\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(100000)\n",
    "\n",
    "    ds = ds.padded_batch(batch_size, ds.output_shapes).repeat(num_epochs)\n",
    "\n",
    "    return ds.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the vocabulary file.\n",
    "terms_url = 'https://download.mlcc.google.com/mledu-datasets/sparse-data-embedding/terms.txt'\n",
    "terms_path = tf.keras.utils.get_file(terms_url.split('/')[-1], terms_url)\n",
    "\n",
    "vocab = None\n",
    "with io.open(terms_path, 'r', encoding='utf8') as f:\n",
    "    vocab = list(set(f.read().split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up feature columns\n",
    "terms_feature_column = tf.feature_column.categorical_column_with_vocabulary_list(key='terms', \n",
    "                                                                                 vocabulary_list=vocab)\n",
    "\n",
    "terms_embedding_column = tf.feature_column.embedding_column(terms_feature_column, dimension=10)\n",
    "feature_columns = [terms_embedding_column]\n",
    "\n",
    "# create estimator spec\n",
    "def make_model(features, labels, mode):\n",
    "\n",
    "    net = tf.feature_column.input_layer(features, feature_columns)\n",
    "    net = tf.layers.dense(net, units=10, activation=tf.nn.leaky_relu)\n",
    "    net = tf.layers.dropout(net, rate=0.3, training=(mode == tf.estimator.ModeKeys.TRAIN))\n",
    "    net = tf.layers.dense(net, units=10)\n",
    "    logits = tf.layers.dense(net, 2)\n",
    "    \n",
    "    # compute predictions\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "    predicted_probs = tf.nn.softmax(logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'class': predicted_classes,\n",
    "            'prob': predicted_probs\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode, \n",
    "                                          predictions=predictions,           \n",
    "                                          export_outputs = {\n",
    "                                              'predict': tf.estimator.export.PredictOutput(outputs=predictions)\n",
    "                                          })\n",
    "\n",
    "    # compute loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # create training op with cosine annealing for learning rate\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        global_step = tf.train.get_global_step()\n",
    "        learning_rate = tf.train.cosine_decay(learning_rate=0.2, global_step=global_step, alpha=0.01, decay_steps=10000)\n",
    "        optimizer = tf.train.AdagradOptimizer(learning_rate=learning_rate)\n",
    "        optimizer = tf.contrib.estimator.clip_gradients_by_norm(optimizer, 5.0)\n",
    "        train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # compute evaluation metrics\n",
    "    eval_metric_ops = {\n",
    "        'accuracy': tf.metrics.accuracy(labels=labels, predictions=predicted_classes),\n",
    "        'auc': tf.metrics.auc(labels=labels, predictions=predicted_probs[:, 1])\n",
    "    }\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n",
    "# create estimator\n",
    "classifier = tf.estimator.Estimator(model_fn=make_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f73fc899cc0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train\n",
    "classifier.train(input_fn=lambda: input_fn([train_path], num_epochs=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.923720</td>\n",
       "      <td>0.867640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>auc</th>\n",
       "      <td>0.973638</td>\n",
       "      <td>0.941962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss</th>\n",
       "      <td>0.205227</td>\n",
       "      <td>0.335154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_step</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    train          test\n",
       "accuracy         0.923720      0.867640\n",
       "auc              0.973638      0.941962\n",
       "loss             0.205227      0.335154\n",
       "global_step  10000.000000  10000.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_stats = classifier.evaluate(input_fn=lambda: input_fn([train_path], num_epochs=1))\n",
    "test_stats = classifier.evaluate(input_fn=lambda: input_fn([test_path], num_epochs=1))\n",
    "\n",
    "train_stats = pd.DataFrame.from_dict(train_stats, orient='index', columns=['train'])\n",
    "test_stats = pd.DataFrame.from_dict(test_stats, orient='index', columns=['test'])\n",
    "stats = train_stats.join(test_stats)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_receiver_fn():\n",
    "    reviews = tf.placeholder(dtype=tf.string, shape=(None), name='reviews')\n",
    "\n",
    "# NOTE: py_func is NOT serialized in the GraphDef, so can't use in serving!\n",
    "#       need to find a different way to do some of our word pre-processing\n",
    "#     @functools.partial(np.vectorize, otypes=[object])\n",
    "#     def tokenize(x):\n",
    "#         return '~'.join(re.compile(r\"[\\w]+|['.,!?;]\").findall(x.decode('utf-8')))\n",
    "    \n",
    "#     terms = tf.py_func(tokenize, [reviews], tf.string, name='tokenize')\n",
    "#     terms = tf.sparse_tensor_to_dense(tf.string_split(reviews, delimiter='~'), default_value='')\n",
    "\n",
    "    terms = tf.sparse_tensor_to_dense(tf.string_split(reviews), default_value='')\n",
    "    return tf.estimator.export.ServingInputReceiver({'terms': terms}, {'reviews': reviews})\n",
    "\n",
    "\n",
    "export_path = classifier.export_savedmodel(export_dir_base='exports',\n",
    "                                           serving_input_receiver_fn=serving_input_receiver_fn)\n",
    "\n",
    "export_path = export_path.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2018-08-31 18:18:10.559376: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       " 'Result for output key class:',\n",
       " '[0 1]',\n",
       " 'Result for output key prob:',\n",
       " '[[1.0000000e+00 1.1786348e-10]',\n",
       " ' [3.6376296e-15 1.0000000e+00]]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!saved_model_cli run --input_exprs 'reviews=[\"this is a terrible movie\", \"this is a great movie\"]'  \\\n",
    "--dir $export_path --tag_set serve --signature_def predict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
